{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "headers = ['age','workclass','fnlwgt','education','education-num','marital-status',\n",
    "           'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "           'hours-per-week','native-country','class']\n",
    "adult = pd.read_csv('./datasets/adult.data', \n",
    "                    sep=', ', names=headers, na_values='?', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30162 entries, 0 to 30161\n",
      "Data columns (total 14 columns):\n",
      "age               30162 non-null int64\n",
      "workclass         30162 non-null object\n",
      "education         30162 non-null object\n",
      "education-num     30162 non-null int64\n",
      "marital-status    30162 non-null object\n",
      "occupation        30162 non-null object\n",
      "relationship      30162 non-null object\n",
      "race              30162 non-null object\n",
      "sex               30162 non-null object\n",
      "capital-gain      30162 non-null int64\n",
      "capital-loss      30162 non-null int64\n",
      "hours-per-week    30162 non-null int64\n",
      "native-country    30162 non-null object\n",
      "class             30162 non-null object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Drop all records with missing values\n",
    "adult.dropna(inplace=True)\n",
    "adult.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Drop fnlwgt, not interesting for ML\n",
    "adult.drop('fnlwgt', axis=1, inplace=True)\n",
    "adult.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert objects to categories\n",
    "# Education is ordered\n",
    "ordered_education = ['Preschool','1st-4th','5th-6th','7th-8th','9th',\n",
    "                    '10th','11th','12th','HS-grad','Assoc-acdm',\n",
    "                     'Assoc-voc','Some-college','Bachelors','Prof-school',\n",
    "                     'Masters','Doctorate']\n",
    "adult['education'] = adult['education'].astype(pd.api.types.CategoricalDtype(categories=ordered_education, ordered=True))\n",
    "\n",
    "#Hours per week is\n",
    "\n",
    "# The rest are not\n",
    "obj_columns = adult.select_dtypes(['object']).columns\n",
    "adult[obj_columns] = adult[obj_columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30162 entries, 0 to 30161\n",
      "Data columns (total 14 columns):\n",
      "age               30162 non-null float64\n",
      "workclass         30162 non-null category\n",
      "education         30162 non-null category\n",
      "education-num     30162 non-null float64\n",
      "marital-status    30162 non-null category\n",
      "occupation        30162 non-null category\n",
      "relationship      30162 non-null category\n",
      "race              30162 non-null category\n",
      "sex               30162 non-null category\n",
      "capital-gain      30162 non-null float64\n",
      "capital-loss      30162 non-null float64\n",
      "hours-per-week    30162 non-null float64\n",
      "native-country    30162 non-null category\n",
      "class             30162 non-null int8\n",
      "dtypes: category(8), float64(5), int8(1)\n",
      "memory usage: 1.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.534247</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.021740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.684932</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.520548</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.726027</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.383562</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.506849</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.671233</td>\n",
       "      <td>Private</td>\n",
       "      <td>9th</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163265</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.712329</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459184</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.424658</td>\n",
       "      <td>Private</td>\n",
       "      <td>Masters</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.140841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.575342</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.051781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.506849</td>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.410959</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>India</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.315068</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.438356</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.465753</td>\n",
       "      <td>Private</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459184</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.342466</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.438356</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.520548</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.589041</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Masters</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459184</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.547945</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age         workclass     education  education-num  \\\n",
       "0   0.534247         State-gov     Bachelors       0.866667   \n",
       "1   0.684932  Self-emp-not-inc     Bachelors       0.866667   \n",
       "2   0.520548           Private       HS-grad       0.600000   \n",
       "3   0.726027           Private          11th       0.466667   \n",
       "4   0.383562           Private     Bachelors       0.866667   \n",
       "5   0.506849           Private       Masters       0.933333   \n",
       "6   0.671233           Private           9th       0.333333   \n",
       "7   0.712329  Self-emp-not-inc       HS-grad       0.600000   \n",
       "8   0.424658           Private       Masters       0.933333   \n",
       "9   0.575342           Private     Bachelors       0.866667   \n",
       "10  0.506849           Private  Some-college       0.666667   \n",
       "11  0.410959         State-gov     Bachelors       0.866667   \n",
       "12  0.315068           Private     Bachelors       0.866667   \n",
       "13  0.438356           Private    Assoc-acdm       0.800000   \n",
       "14  0.465753           Private       7th-8th       0.266667   \n",
       "15  0.342466  Self-emp-not-inc       HS-grad       0.600000   \n",
       "16  0.438356           Private       HS-grad       0.600000   \n",
       "17  0.520548           Private          11th       0.466667   \n",
       "18  0.589041  Self-emp-not-inc       Masters       0.933333   \n",
       "19  0.547945           Private     Doctorate       1.066667   \n",
       "\n",
       "           marital-status         occupation   relationship  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife   \n",
       "5      Married-civ-spouse    Exec-managerial           Wife   \n",
       "6   Married-spouse-absent      Other-service  Not-in-family   \n",
       "7      Married-civ-spouse    Exec-managerial        Husband   \n",
       "8           Never-married     Prof-specialty  Not-in-family   \n",
       "9      Married-civ-spouse    Exec-managerial        Husband   \n",
       "10     Married-civ-spouse    Exec-managerial        Husband   \n",
       "11     Married-civ-spouse     Prof-specialty        Husband   \n",
       "12          Never-married       Adm-clerical      Own-child   \n",
       "13          Never-married              Sales  Not-in-family   \n",
       "14     Married-civ-spouse   Transport-moving        Husband   \n",
       "15          Never-married    Farming-fishing      Own-child   \n",
       "16          Never-married  Machine-op-inspct      Unmarried   \n",
       "17     Married-civ-spouse              Sales        Husband   \n",
       "18               Divorced    Exec-managerial      Unmarried   \n",
       "19     Married-civ-spouse     Prof-specialty        Husband   \n",
       "\n",
       "                  race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                White    Male      0.021740           0.0        0.408163   \n",
       "1                White    Male      0.000000           0.0        0.132653   \n",
       "2                White    Male      0.000000           0.0        0.408163   \n",
       "3                Black    Male      0.000000           0.0        0.408163   \n",
       "4                Black  Female      0.000000           0.0        0.408163   \n",
       "5                White  Female      0.000000           0.0        0.408163   \n",
       "6                Black  Female      0.000000           0.0        0.163265   \n",
       "7                White    Male      0.000000           0.0        0.459184   \n",
       "8                White  Female      0.140841           0.0        0.510204   \n",
       "9                White    Male      0.051781           0.0        0.408163   \n",
       "10               Black    Male      0.000000           0.0        0.816327   \n",
       "11  Asian-Pac-Islander    Male      0.000000           0.0        0.408163   \n",
       "12               White  Female      0.000000           0.0        0.306122   \n",
       "13               Black    Male      0.000000           0.0        0.510204   \n",
       "14  Amer-Indian-Eskimo    Male      0.000000           0.0        0.459184   \n",
       "15               White    Male      0.000000           0.0        0.357143   \n",
       "16               White    Male      0.000000           0.0        0.408163   \n",
       "17               White    Male      0.000000           0.0        0.510204   \n",
       "18               White  Female      0.000000           0.0        0.459184   \n",
       "19               White    Male      0.000000           0.0        0.612245   \n",
       "\n",
       "   native-country  class  \n",
       "0   United-States      0  \n",
       "1   United-States      0  \n",
       "2   United-States      0  \n",
       "3   United-States      0  \n",
       "4            Cuba      0  \n",
       "5   United-States      0  \n",
       "6         Jamaica      0  \n",
       "7   United-States      1  \n",
       "8   United-States      1  \n",
       "9   United-States      1  \n",
       "10  United-States      1  \n",
       "11          India      1  \n",
       "12  United-States      0  \n",
       "13  United-States      0  \n",
       "14         Mexico      0  \n",
       "15  United-States      0  \n",
       "16  United-States      0  \n",
       "17  United-States      0  \n",
       "18  United-States      1  \n",
       "19  United-States      1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert numerics to floats and normalize\n",
    "num_columns = adult.select_dtypes(['int64']).columns\n",
    "adult[num_columns] = adult[num_columns].astype('float64')\n",
    "for c in num_columns:\n",
    "    #adult[c] -= adult[c].mean()\n",
    "    #adult[c] /= adult[c].std()\n",
    "    adult[c] /= (adult[c].max()-adult[c].min())\n",
    "adult['class'] = adult['class'].cat.codes\n",
    "display(adult.info())\n",
    "display(adult.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.534247</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.684932</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.520548</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.726027</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.383562</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age         workclass  education  education-num      marital-status  \\\n",
       "0  0.534247         State-gov  Bachelors       0.866667       Never-married   \n",
       "1  0.684932  Self-emp-not-inc  Bachelors       0.866667  Married-civ-spouse   \n",
       "2  0.520548           Private    HS-grad       0.600000            Divorced   \n",
       "3  0.726027           Private       11th       0.466667  Married-civ-spouse   \n",
       "4  0.383562           Private  Bachelors       0.866667  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male       0.02174   \n",
       "1    Exec-managerial        Husband  White    Male       0.00000   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male       0.00000   \n",
       "3  Handlers-cleaners        Husband  Black    Male       0.00000   \n",
       "4     Prof-specialty           Wife  Black  Female       0.00000   \n",
       "\n",
       "   capital-loss  hours-per-week native-country  class  \n",
       "0           0.0        0.408163  United-States      0  \n",
       "1           0.0        0.132653  United-States      0  \n",
       "2           0.0        0.408163  United-States      0  \n",
       "3           0.0        0.408163  United-States      0  \n",
       "4           0.0        0.408163           Cuba      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('num', 'passthrough', [0, 3, 9, 10, 11]), ('cat', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "       n_values=None, sparse=True), [1, 2, 4, 5, 6, 7, 8, 12])])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "display(adult.head())\n",
    "enc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', [0, 3, 9, 10, 11]),\n",
    "        #('num', 'passthrough', [0, 2, 8, 9, 10]),\n",
    "        ('cat', OneHotEncoder(), [1, 2, 4, 5, 6, 7, 8, 12]),])\n",
    "        #('cat', OneHotEncoder(), [1, 3, 4, 5, 6, 7, 11]),])\n",
    "        #('label', LabelEncoder(), 13)])\n",
    "\n",
    "enc.fit(adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(adult.drop('class', axis=1), adult['class'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load semantic distances from files\n",
    "\n",
    "import os\n",
    "import collections\n",
    "\n",
    "#path = './datasets/semdist/ontodistnolog/'\n",
    "#path = './datasets/semdist/ontodist/'\n",
    "path = './datasets/semdist/embedist/'\n",
    "categorical_attributes = list(adult.select_dtypes(['category']).columns.values)\n",
    "categorical_attributes = categorical_attributes[:-1]\n",
    "\n",
    "distances = {}\n",
    "for categorical_attribute in categorical_attributes:\n",
    "    with open(path+categorical_attribute+'.txt') as f:\n",
    "        contents = list(f)\n",
    "        categories = list(map(str.strip, contents[0].split(',')))\n",
    "        m = []\n",
    "        for line in contents[1:]:\n",
    "            m.append(list(map(float, map(str.strip, line.split(',')))))\n",
    "        d = collections.defaultdict(dict)\n",
    "        for i in range(len(categories)):\n",
    "            for j in range(len(categories)):\n",
    "                d[categories[i]][categories[j]] = m[i][j]\n",
    "        distances[categorical_attribute] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# current best results embedist/weight/nosquare\n",
    "def dist_attr(x, y, attr_pos, categorical_mask, column_names):\n",
    "    if categorical_mask[attr_pos]:\n",
    "        #return 0.625 * distances[column_names[attr_pos]][x[attr_pos]][y[attr_pos]]**2\n",
    "        #return distances[column_names[attr_pos]][x[attr_pos]][y[attr_pos]]**2\n",
    "        #return 0.625 * distances[column_names[attr_pos]][x[attr_pos]][y[attr_pos]]\n",
    "        return distances[column_names[attr_pos]][x[attr_pos]][y[attr_pos]]\n",
    "    else:\n",
    "        #return (float(x[attr_pos]) - float(y[attr_pos]))**2\n",
    "        return abs(float(x[attr_pos]) - float(y[attr_pos]))\n",
    "\n",
    "def dist_record(x, y):\n",
    "    d = []\n",
    "    categorical_mask = [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
    "    #categorical_mask = [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1]\n",
    "    column_names = list(adult.columns.values)[:-1]\n",
    "    for i in range(len(column_names)):\n",
    "        d.append(dist_attr(x, y, i, categorical_mask, column_names))\n",
    "    \n",
    "    #return float(math.sqrt(sum(d)))\n",
    "    return float(sum(d))\n",
    "    \n",
    "def mean_record(D):\n",
    "    d = []\n",
    "    # 0->age \n",
    "    d.append(float(np.mean(D[:,0])))\n",
    "    # 1->workclass  \n",
    "    d.append(mean_semantic(D[:,1], 'workclass'))\n",
    "    # 2->education \n",
    "    d.append(mean_semantic(D[:,2], 'education'))\n",
    "    # 3->education-num   \n",
    "    d.append(float(np.mean(D[:,3])))\n",
    "    # 4->marital-status  \n",
    "    d.append(mean_semantic(D[:,4], 'marital-status'))\n",
    "    # 5->occupation  \n",
    "    d.append(mean_semantic(D[:,5], 'occupation'))\n",
    "    # 6->relationship \n",
    "    d.append(mean_semantic(D[:,6], 'relationship'))\n",
    "    # 7->race    \n",
    "    d.append(mean_semantic(D[:,7], 'race'))\n",
    "    # 8->sex  \n",
    "    d.append(mean_semantic(D[:,8], 'sex'))\n",
    "    # 9->capital-gain  \n",
    "    d.append(float(np.mean(D[:,9])))\n",
    "    #10->capital-loss \n",
    "    d.append(float(np.mean(D[:,10])))\n",
    "    #11->hours-per-week \n",
    "    d.append(float(np.mean(D[:,11])))\n",
    "    #12->native-country  \n",
    "    d.append(mean_semantic(D[:,12], 'native-country'))\n",
    "    \n",
    "    return d\n",
    "    \n",
    "def mean_semantic(values, attribute_name):\n",
    "    candidates = list(distances[attribute_name].keys())\n",
    "    return values[np.argmin([sum([distances[attribute_name][c][v] for c in candidates]) for v in values])]\n",
    "\n",
    "def dist(x,y):\n",
    "    return np.linalg.norm(x-y)\n",
    "    #return scipy.spatial.distance.correlation(x,y)\n",
    "\n",
    "def poprow(arr,i):\n",
    "    pop = arr[i]\n",
    "    new_array = np.vstack((arr[:i],arr[i+1:]))\n",
    "    return new_array,pop\n",
    "\n",
    "def cluster(X, p, k):\n",
    "    c = [p]\n",
    "    D = np.column_stack((X,[dist_record(v[:-1],p[:-1]) for v in X]))\n",
    "    D = D[D[:,-1].argsort()]\n",
    "    D = np.delete(D, -1, 1)\n",
    "    c.extend(D[:k-1])\n",
    "    D = D[k-1:]\n",
    "    \n",
    "    xc = np.array([p[:-1] for p in c], copy=False, ndmin=2)\n",
    "    yc = np.array([p[-1] for p in c], copy=False)\n",
    "    cl = (xc, yc)\n",
    "    return D, cl\n",
    "    \n",
    "def mdav(X, y, k):\n",
    "    D = np.column_stack((X,y))\n",
    "    clusters = []\n",
    "    while len(D) >= 3*k:\n",
    "        # Centroid\n",
    "        xm = mean_record(D)\n",
    "        # Furthest from centroid\n",
    "        xri = np.argmax([dist_record(v[:-1],xm) for v in D])\n",
    "        D, xr = poprow(D, xri)\n",
    "        # Furthest from furthest from centroid\n",
    "        xsi = np.argmax([dist_record(v[:-1],xr[:-1]) for v in D])\n",
    "        D, xs = poprow(D, xsi) \n",
    "\n",
    "        #cluster of xr\n",
    "        D, c = cluster(D, xr, k)\n",
    "        clusters.append(c)\n",
    "        #cluster of xs\n",
    "        D, c = cluster(D, xs, k)\n",
    "        clusters.append(c)\n",
    "        \n",
    "    if len(D) >= 2*k and len(D) < 3*k:\n",
    "        # Centroid\n",
    "        xm = mean_record(D)\n",
    "        # Furthest from centroid\n",
    "        xri = np.argmax([dist_record(v[:-1],xm) for v in D])\n",
    "        D, xr = poprow(D, xri)\n",
    "        #cluster of xr\n",
    "        D, c = cluster(D, xr, k)\n",
    "        clusters.append(c)\n",
    "        \n",
    "        # rest of points\n",
    "        xc = np.array([p[:-1] for p in D[:]], copy=False, ndmin=2)\n",
    "        yc = np.array([p[-1] for p in D[:]], copy=False)\n",
    "        cl = (xc, yc)\n",
    "        clusters.append(cl)     \n",
    "    else:\n",
    "        # rest of points\n",
    "        xc = np.array([p[:-1] for p in D[:]], copy=False, ndmin=2)\n",
    "        yc = np.array([p[-1] for p in D[:]], copy=False)\n",
    "        cl = (xc, yc)\n",
    "        clusters.append(cl)\n",
    "    \n",
    "    centroids = np.array([mean_record(c[0]) for c in clusters], copy=False)\n",
    "    \n",
    "    return clusters, centroids\n",
    "\n",
    "from sklearn import tree\n",
    "def gen_explanations(clustering, max_depth=-1):\n",
    "    explanations = []\n",
    "    for cluster in clustering:\n",
    "        # Testing with max depth\n",
    "        if max_depth < 1:\n",
    "            exp = tree.DecisionTreeClassifier()\n",
    "        else:\n",
    "            exp = tree.DecisionTreeClassifier(max_depth=max_depth)\n",
    "        exp.fit(enc.transform(cluster[0]),cluster[1])\n",
    "        explanations.append(exp) \n",
    "    return explanations\n",
    "\n",
    "def pre_explanations(explanations, centroids, X):\n",
    "    predictions = []\n",
    "    for sample in X:\n",
    "        #select the closest classifier\n",
    "        exp = explanations[np.argmin([dist_record(sample,c) for c in centroids])]\n",
    "        #exp_pred = exp.predict([sample])\n",
    "        exp_pred = exp.predict(enc.transform([sample]))\n",
    "        predictions.append(exp_pred[0])\n",
    "    return predictions\n",
    "\n",
    "def pre_explanations_ext(explanations, centroids, X, T, n):\n",
    "    predictions = []\n",
    "    for sample, truth in zip(X,T):\n",
    "        #select the 3 closest classifiers\n",
    "        mins = np.array([dist_record(sample,c) for c in centroids]).argsort()[:n]\n",
    "        for m in mins:\n",
    "            exp = explanations[m]\n",
    "            #exp_pred = exp.predict([sample])\n",
    "            exp_pred = exp.predict(enc.transform([sample]))\n",
    "            if(exp_pred[0] == truth):\n",
    "                break\n",
    "        predictions.append(exp_pred[0])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'native-country'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-02d16b87dfcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcentroids_of_clusterings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mclustering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mclusterings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mcentroids_of_clusterings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-2c18c8804340>\u001b[0m in \u001b[0;36mmdav\u001b[1;34m(X, y, k)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;31m# Centroid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mxm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Furthest from centroid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mxri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdist_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mxm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-2c18c8804340>\u001b[0m in \u001b[0;36mmean_record\u001b[1;34m(D)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m#12->native-country\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_semantic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'native-country'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-2c18c8804340>\u001b[0m in \u001b[0;36mmean_semantic\u001b[1;34m(values, attribute_name)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmean_semantic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattribute_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mcandidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'native-country'"
     ]
    }
   ],
   "source": [
    "# Generate clusters for different representativities\n",
    "representativity = [0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "K = [int(len(X_train)*r) for r in representativity]\n",
    "clusterings = []\n",
    "centroids_of_clusterings = []\n",
    "for k in K:\n",
    "    clustering, centroids = mdav(X_train, y_train, k)\n",
    "    clusterings.append(clustering)\n",
    "    centroids_of_clusterings.append(centroids)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train explanations\n",
    "clu_explanations = []\n",
    "for clustering in clusterings:\n",
    "    # Test shallow trees depht=4\n",
    "    explanations = gen_explanations(clustering, 4)\n",
    "    clu_explanations.append(explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'CategoricalDtype' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5de610052185>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m blackbox = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n\u001b[0;32m      4\u001b[0m                      solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mblackbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblackbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alber\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    975\u001b[0m         \"\"\"\n\u001b[0;32m    976\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[1;32m--> 977\u001b[1;33m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alber\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    322\u001b[0m                              hidden_layer_sizes)\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alber\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    912\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 914\u001b[1;33m                          multi_output=True)\n\u001b[0m\u001b[0;32m    915\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alber\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[1;32m--> 759\u001b[1;33m                         dtype=None)\n\u001b[0m\u001b[0;32m    760\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alber\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;31m# DataFrame), and store them. If not, store None.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[0mdtypes_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtypes\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m         \u001b[0mdtypes_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'CategoricalDtype' has no len()"
     ]
    }
   ],
   "source": [
    "# Train blackbox model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "blackbox = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)\n",
    "blackbox.fit(enc.transform(X_train), y_train)\n",
    "display(blackbox.score(enc.transform(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'CategoricalDtype' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-bc2472e041fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train big tree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msurrogate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msurrogate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msurrogate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msurrogate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alber\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    802\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alber\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alber\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[1;31m# DataFrame), and store them. If not, store None.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[0mdtypes_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtypes\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m         \u001b[0mdtypes_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'CategoricalDtype' has no len()"
     ]
    }
   ],
   "source": [
    "# Train big tree\n",
    "surrogate = tree.DecisionTreeClassifier()\n",
    "surrogate.fit(enc.transform(X_train),y_train)\n",
    "display(surrogate.score(enc.transform(X_test), y_test))\n",
    "display(surrogate.tree_.node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = y_test\n",
    "blackbox_predictions = blackbox.predict(enc.transform(X_test))\n",
    "surrogate_predictions = surrogate.predict(enc.transform(X_test))\n",
    "explanation_predictions = []\n",
    "explanation_ext_predictions = []\n",
    "for i in range(len(clu_explanations)):\n",
    "    p = pre_explanations(clu_explanations[i], centroids_of_clusterings[i], np.array(X_test))\n",
    "    q = pre_explanations_ext(clu_explanations[i], centroids_of_clusterings[i], np.array(X_test), blackbox_predictions, 3)\n",
    "    explanation_predictions.append(p)\n",
    "    explanation_ext_predictions.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# acc = TP+TN/all\n",
    "acc_blackbox = np.mean([t==p for t,p in zip(truth, blackbox_predictions)])\n",
    "acc_surrogate = np.mean([t==p for t,p in zip(truth, surrogate_predictions)])\n",
    "acc_explanations = []\n",
    "for i in range(len(explanation_predictions)):\n",
    "    acc_explanations.append(np.mean([t==p for t,p in zip(truth, explanation_predictions[i])]))\n",
    "    \n",
    "acc_explanations_ext = []\n",
    "for i in range(len(explanation_ext_predictions)):\n",
    "    acc_explanations_ext.append(np.mean([t==p for t,p in zip(truth, explanation_ext_predictions[i])]))\n",
    "\n",
    "acc_cross = []\n",
    "for i in range(len(explanation_predictions)):\n",
    "    acc_cross.append(np.mean([t==p for t,p in zip(blackbox_predictions, explanation_predictions[i])]))\n",
    "\n",
    "acc_cross_ext = []\n",
    "for i in range(len(explanation_predictions)):\n",
    "    acc_cross_ext.append(np.mean([t==p for t,p in zip(blackbox_predictions, explanation_ext_predictions[i])]))\n",
    "\n",
    "display(acc_blackbox)\n",
    "display(acc_explanations)\n",
    "display(acc_explanations_ext)\n",
    "display(acc_cross)\n",
    "display(acc_cross_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_nodes = []\n",
    "max_nodes = []\n",
    "mean_nodes = []\n",
    "median_nodes = []\n",
    "n_counts = []\n",
    "for explanations in clu_explanations:\n",
    "    node_counts = [exp.tree_.node_count for exp in explanations]\n",
    "    n_counts.append(node_counts)\n",
    "    min_nodes.append(np.min(node_counts))\n",
    "    max_nodes.append(np.max(node_counts))\n",
    "    mean_nodes.append(np.mean(node_counts))\n",
    "    median_nodes.append(np.median(node_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "\n",
    "representativity = [0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "representativity = list([r*100 for r in representativity])\n",
    "\n",
    "xnew = np.linspace(min(representativity),max(representativity),300)\n",
    "spl = make_interp_spline(representativity, acc_explanations, k=3) #BSpline object\n",
    "ynew = spl(xnew)\n",
    "\n",
    "spl = make_interp_spline(representativity, acc_explanations_ext, k=3) #BSpline object\n",
    "ynew4 = spl(xnew)\n",
    "\n",
    "acc_blackbox_const = [acc_blackbox]*len(representativity)\n",
    "spl = make_interp_spline(representativity, acc_blackbox_const, k=3) #BSpline object\n",
    "ynew2 = spl(xnew)\n",
    "\n",
    "big_tree = [acc_surrogate]*len(representativity)\n",
    "spl = make_interp_spline(representativity, big_tree, k=3) #BSpline object\n",
    "ynew6 = spl(xnew)\n",
    "\n",
    "spl = make_interp_spline(representativity, acc_cross, k=3) #BSpline object\n",
    "ynew3 = spl(xnew)\n",
    "\n",
    "spl = make_interp_spline(representativity, acc_cross_ext, k=3) #BSpline object\n",
    "ynew5 = spl(xnew)\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.plot(xnew,ynew2,linestyle='-',linewidth=3,color='k',label='ANN')\n",
    "plt.plot(xnew,ynew6,linestyle='-.',linewidth=3,color='k',label='Global DT')\n",
    "plt.plot(xnew,ynew,linestyle=':',linewidth=3,color='k',label='Unguided DT')\n",
    "#plt.plot(xnew,ynew3, label='interpretable w.r.t. blackbox')\n",
    "plt.plot(xnew,ynew4,linestyle='--',linewidth=3,color='k',label='Guided DT')\n",
    "\n",
    "#plt.plot(xnew,ynew5, label='interpretable-guided w.r.t. blackbox')\n",
    "\n",
    "\n",
    "plt.legend(handlelength=4)\n",
    "plt.ylim(0.7,0.9)\n",
    "plt.xlabel('% of records per cluster')\n",
    "plt.ylabel('classification accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "##plt.plot(xnew,ynew2, label='blackbox')\n",
    "##plt.plot(xnew,ynew, label='interpretable')\n",
    "plt.plot(xnew,ynew3,linestyle='-',linewidth=3,color='k',label='Unguided DT w.r.t. ANN predictions')\n",
    "##plt.plot(xnew,ynew4, label='interpretable-guided')\n",
    "plt.plot(xnew,ynew5,linestyle=':',linewidth=3,color='k',label='Guided DT w.r.t. ANN predictions')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(0.7,1)\n",
    "plt.xlabel('% of records per cluster')\n",
    "plt.ylabel('classification accuracy')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xnew,make_interp_spline(representativity, min_nodes, k=3)(xnew),label='min')\n",
    "plt.plot(xnew,make_interp_spline(representativity, max_nodes, k=3)(xnew),label='max')\n",
    "plt.plot(xnew,make_interp_spline(representativity, mean_nodes, k=3)(xnew),label='mean')\n",
    "plt.plot(xnew,make_interp_spline(representativity, median_nodes, k=3)(xnew),label='median')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "plt.boxplot(n_counts)\n",
    "locs, _ = plt.xticks()\n",
    "plt.xticks(locs, representativity)\n",
    "#plt.yscale('log')\n",
    "plt.xlabel('% of records per cluster')\n",
    "plt.ylabel('number of nodes')\n",
    "#plt.ylabel('number of nodes (log scale)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "for clu_explanation in clu_explanations:\n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(clu_explanation[0], out_file=dot_data,  \n",
    "                    filled=True, rounded=True,\n",
    "                    special_characters=True)\n",
    "\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    display(Image(graph.create_png()))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
